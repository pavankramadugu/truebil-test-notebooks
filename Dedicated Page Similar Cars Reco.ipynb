{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import redis\n",
    "import pickle\n",
    "import itertools\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.sparse as sp\n",
    "\n",
    "seen_car_ids = None\n",
    "seen_car_ids = seen_car_ids and list(seen_car_ids)\n",
    "__always_supported = ('md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512')\n",
    "\n",
    "class ModelData:\n",
    "    user_features = 'user_features'\n",
    "    item_features = 'item_features'\n",
    "    trained_model = 'model'\n",
    "    popular_listings = 'popular_listings'\n",
    "    max_buyer_id = 'max_buyer_id'\n",
    "    active_listings = 'active_listings'\n",
    "\n",
    "df=pd.read_csv('/home/pavank/Desktop/mumbai.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_ORDER_LISTINGS_STATUSES = ['active', 'refurbishing']\n",
    "\n",
    "def pandas_cached_query(query, disable_cache=False):\n",
    "    if disable_cache:\n",
    "        return pd.read_sql_query(query, connection)\n",
    "    key = sha1(query).hexdigest()\n",
    "    if key in cache:\n",
    "        return cache.get(key)\n",
    "    else:\n",
    "        data = pd.read_sql_query(query, connection)\n",
    "        cache.set(key, data, timeout=Settings.CACHALOT_TIMEOUT)\n",
    "        return data\n",
    "    \n",
    "LISTING_FEATURE_QUERY = \"\"\"SELECT listings.id, localities.city_id, IFNULL(price, 0) < 200000 AS price_b_2,\n",
    "                           IFNULL(price, 0) BETWEEN 100000 AND 300000 AS price_bw_1_3, IFNULL(price, 0) BETWEEN 200000\n",
    "                           AND 400000 AS price_bw_2_4, IFNULL(price, 0) BETWEEN 300000 AND 500000 AS price_bw_3_5,\n",
    "                           IFNULL(price, 0) BETWEEN 400000 AND 600000 AS price_bw_4_6, IFNULL(price, 0) BETWEEN 500000\n",
    "                           AND 700000 AS price_bw_5_7, IFNULL(price, 0) BETWEEN 600000 AND 800000 AS price_bw_6_8,\n",
    "                           IFNULL(price, 0) BETWEEN 700000 AND 900000 AS price_bw_7_9, IFNULL(price, 0) > 900000 AS\n",
    "                           price_a_9, IFNULL(listings.body_type_id = 1, 0) AS hatchback, IFNULL(listings.body_type_id = \n",
    "                           2, 0) AS sedan, IFNULL(listings.body_type_id = 3, 0) AS mpv, IFNULL(listings.body_type_id = \n",
    "                           4, 0) AS suv, listings.fuel_type_id_primary = 1 AS petrol, listings.fuel_type_id_primary = 2 \n",
    "                           AS diesel, IFNULL(owners, 0) = 1 AS first_owner, IFNULL(owners, 0) > 1 AS owner, \n",
    "                           IFNULL(mileage, 0) <= 30000 AS mileage_b_3, IFNULL(mileage, 0) BETWEEN 30001 AND 70000 AS \n",
    "                           mileage_bw_3_7, IFNULL(mileage, 0) > 70000 AS mileage_a_7, IFNULL(year(curdate())-\n",
    "                           year(registration_date), 0) <= 2 AS age_b_2, IFNULL(year(curdate())-year(registration_date), \n",
    "                           0) BETWEEN 3 AND 4 AS age_bw_3_4, IFNULL (year(curdate())- year(registration_date), 0) \n",
    "                           BETWEEN 5 AND 7 AS age_bw_5_7, IFNULL(year(curdate())- year(registration_date), 0)>7 AS \n",
    "                           age_a_7,  IFNULL(variants.model_id, 0) IN (SELECT variants.model_id FROM listings JOIN \n",
    "                           variants ON listings.variant_id=variants.id WHERE listings.id IN ({listing_ids})) AS model_id,\n",
    "                           IFNULL(variants.id, 0) IN (SELECT variants.id FROM listings JOIN variants ON listings.\n",
    "                           variant_id=variants.id WHERE listings.id IN ({listing_ids})) AS variant_id, IFNULL(listings.\n",
    "                           color_id, 0) IN (1 , 3, 6) AS color_wsg, IFNULL(listings.color_id, 0) IN (2 , 13) AS color_bo,\n",
    "                           IFNULL(listings.color_id, 0) NOT IN (1 , 2, 3, 6, 13) AS color_rest, IFNULL(CAST(listings.\n",
    "                           is_inventory AS UNSIGNED), 0) AS is_inventory, price, created_at FROM listings JOIN \n",
    "                           localities ON listings.locality_id = localities.id JOIN variants ON listings.variant_id = \n",
    "                           variants.id where {filter_query}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'sha1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5911e5a0c20a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpandas_cached_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLISTING_FEATURE_QUERY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-f597453a4e73>\u001b[0m in \u001b[0;36mpandas_cached_query\u001b[0;34m(query, disable_cache)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdisable_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msha1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'sha1' is not defined"
     ]
    }
   ],
   "source": [
    "pandas_cached_query(LISTING_FEATURE_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_model(number):\n",
    "    pool = redis.ConnectionPool(host=\"127.0.0.1\", port=6379, db=1)\n",
    "    redis_connection = redis.Redis(connection_pool=pool)\n",
    "    ModelData.trained_model = pickle.loads(redis_connection.get('model'))\n",
    "    ModelData.user_features = pickle.loads(redis_connection.get('user_features'))\n",
    "    ModelData.item_features = pickle.loads(redis_connection.get('item_features'))\n",
    "    ModelData.max_buyer_id = redis_connection.get('max_buyer_id')\n",
    "    ModelData.popular_listings = pickle.loads(redis_connection.get('popular_listings'))\n",
    "    ModelData.active_listings = pickle.loads(redis_connection.get('active_listings'))\n",
    "    ModelData.pd_lt_2_set = pickle.loads(redis_connection.get('pd_lt_2_set'))\n",
    "    ModelData.make_model_dict = ast.literal_eval(redis_connection.get('make_model_dict'))\n",
    "    ModelData.features_dict = ast.literal_eval(redis_connection.get('features_dict'))\n",
    "    ModelData.make_model_spell.word_frequency.load_words(ast.literal_eval(\n",
    "        redis_connection.get('make_model_words')))\n",
    "    ModelData.features_spell.word_frequency.load_words(\n",
    "        ast.literal_eval(redis_connection.get('features_words')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "StringIO() argument 1 must be string or buffer, not None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-653769ad622c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_trained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-05e271fc3813>\u001b[0m in \u001b[0;36mget_trained_model\u001b[0;34m(number)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mModelData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopular_listings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredis_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'popular_listings'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mModelData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_listings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredis_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'active_listings'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mModelData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpd_lt_2_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredis_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pd_lt_2_set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mModelData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_model_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredis_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'make_model_dict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mModelData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredis_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features_dict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pavank/miniconda3/envs/recoenv/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mloads\u001b[0;34m(str)\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1387\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1388\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: StringIO() argument 1 must be string or buffer, not None"
     ]
    }
   ],
   "source": [
    "get_trained_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_listing_features(city_id, listings=None, inactive=False, listing_filter=True):\n",
    "    city_filter = \"\"\"localities.city_id = {city_id}\"\"\".format(city_id=city_id)\n",
    "    listing_id_filter = \"\"\"listings.id in ({listings})\"\"\".format(\n",
    "        listings=','.join(map(str, list(listings)))\n",
    "    ) if listings and listing_filter else None\n",
    "    listing_status_filter = \"\"\"listings.status in {status}\"\"\".format(\n",
    "        status=tuple(TOP_ORDER_LISTINGS_STATUSES)\n",
    "    ) if not inactive else None\n",
    "\n",
    "    filter_array = [city_filter, listing_id_filter, listing_status_filter]\n",
    "\n",
    "    listings_features = pandas_cached_query(\n",
    "        LISTING_FEATURE_QUERY.format(\n",
    "            filter_query=' and '.join(filter(None, filter_array)),\n",
    "            listing_ids=','.join(map(str, listings)) if listings else 0\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_filtered__indices(features, filtered__ids):\n",
    "#     features_mtx = features.tocoo()\n",
    "#     filtered_indices = []\n",
    "#     for item_id, feature_id in itertools.izip(features_mtx.row, features_mtx.col):\n",
    "#         if feature_id in filtered__ids:\n",
    "#             filtered_indices.append(item_id)\n",
    "#     return filtered_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_representations(features=None):\n",
    "    if features is None:\n",
    "        return ModelData.trained_model.item_biases, ModelData.trained_model.item_embeddings\n",
    "\n",
    "    features = sp.csr_matrix(features, dtype=np.float32)\n",
    "\n",
    "    return features * ModelData.trained_model.item_biases, features * ModelData.trained_model.item_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_similar_cars():\n",
    "#     listings = [] \n",
    "#     city_active_listings_ids = df['2743'].tolist()\n",
    "#     for id in city_active_listings_ids:\n",
    "#         seen_car_ids = id\n",
    "#         latest_seen_car_ids = seen_car_ids\n",
    "#         features = ModelData.item_features\n",
    "#         item_embeddings = get_item_representations(features)[1]\n",
    "#         #data = ModelData.trained_model.mapping()[3]\n",
    "\n",
    "# #         filtered_item_ids = [data[id] for id in latest_seen_car_ids]\n",
    "# #         filtered_item_indices = get_filtered__indices(features, filtered_item_ids)\n",
    "#         seen_item_embeddings = [item_embeddings[latest_seen_car_ids - 1]]\n",
    "\n",
    "# #         city_active_listings = get_listing_features(1, listings=latest_seen_car_ids,listing_filter=False)\n",
    "# #         city_active_listings_ids = np.array(city_active_listings)[:, 0]\n",
    "# #         filtered_city_ids = [data[id] for id in city_active_listings_ids]\n",
    "# #         filtered_city_indices = get_filtered__indices(features, filtered_city_ids)\n",
    "#         city_active_listings_embeddings = []\n",
    "#         for i in city_active_listings_ids:\n",
    "#             city_active_listings_embeddings.append(item_embeddings[i - 1])\n",
    "\n",
    "#         max_cosine_scores = -np.ones(len(city_active_listings)).reshape(1, -1)\n",
    "#         for item_embeddings in seen_item_embeddings:\n",
    "#             curr_cosine_scores = cosine_similarity(city_active_listings_embeddings, [item_embeddings]).reshape(1, -1)\n",
    "#             max_cosine_scores = np.maximum(curr_cosine_scores, max_cosine_scores)\n",
    "\n",
    "#         similarity_indices = np.argsort(-max_cosine_scores)\n",
    "#         similar_cars_cosine_scores = max_cosine_scores\n",
    "\n",
    "#         similar_listings = city_active_listings_ids[similarity_indices].ravel()\n",
    "#         listings.append(similar_listings[:4])\n",
    "    \n",
    "#     f = pd.DataFrame(listings)\n",
    "#     f.columns = [\"Listing ID\", \"Reco - 1\", \"Reco - 2\", \"Reco - 3\"]\n",
    "#     f.to_csv('kkk.csv', encoding='utf-8', index=False)\n",
    "#     return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_cars():\n",
    "    listings = [] \n",
    "    coo = []\n",
    "    get_item = []\n",
    "    city_active_listings_ids = df['id'].tolist()\n",
    "    for id in city_active_listings_ids:\n",
    "        seen_car_ids = id\n",
    "        latest_seen_car_ids = seen_car_ids\n",
    "        listings_features = ModelData.item_features\n",
    "        listings_item_embeddings = (listings_features.tocoo()) * ModelData.trained_model.item_embeddings\n",
    "        coo.append(listings_item_embeddings)\n",
    "        embeddings = get_item_representations(listings_features)[1]\n",
    "        get_item.append(embeddings)\n",
    "        seen_item_embeddings = [listings_item_embeddings[latest_seen_car_ids - 1]]\n",
    "        city_active_listings_embeddings = []\n",
    "        for i in city_active_listings_ids:\n",
    "            city_active_listings_embeddings.append(listings_item_embeddings[i - 1])\n",
    "        max_cosine_scores = -np.ones(len(city_active_listings_ids)).reshape(1, -1)\n",
    "        for item_embeddings in seen_item_embeddings:\n",
    "            curr_cosine_scores = cosine_similarity(city_active_listings_embeddings, [item_embeddings]).reshape(1, -1)\n",
    "            max_cosine_scores = np.maximum(curr_cosine_scores, max_cosine_scores)\n",
    "        similarity_indices = np.argsort(-max_cosine_scores)\n",
    "        similar_cars_cosine_scores = max_cosine_scores\n",
    "        city_active_listings_ids = np.array(city_active_listings_ids)\n",
    "        similar_listings = city_active_listings_ids[similarity_indices].ravel()\n",
    "        listings.append(similar_listings[:4])\n",
    "#     f = pd.DataFrame(listings)\n",
    "#     f.columns = [\"Listing ID\", \"Reco - 1\", \"Reco - 2\", \"Reco - 3\"]\n",
    "#     f.to_csv('reco_test.csv', encoding='utf-8', index=False)\n",
    "    return coo, get_item\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'tocoo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a71bb27f7e4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_similar_cars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-0f051af0bf1a>\u001b[0m in \u001b[0;36mget_similar_cars\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlatest_seen_car_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseen_car_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlistings_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mlistings_item_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlistings_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mModelData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mcoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistings_item_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_item_representations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistings_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'tocoo'"
     ]
    }
   ],
   "source": [
    "get_similar_cars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_cars():\n",
    "    listings = [] \n",
    "    city_active_listings_ids = df['2743'].tolist()\n",
    "    for id in city_active_listings_ids:\n",
    "        seen_car_ids = id\n",
    "        latest_seen_car_ids = seen_car_ids\n",
    "        features = ModelData.item_features\n",
    "        listings_item_embeddings = get_item_representations(features)[1]\n",
    "        seen_item_embeddings = [listings_item_embeddings[latest_seen_car_ids - 1]]\n",
    "        city_active_listings_embeddings = []\n",
    "        for i in city_active_listings_ids:\n",
    "            city_active_listings_embeddings.append(listings_item_embeddings[i - 1])\n",
    "        max_cosine_scores = -np.ones(len(city_active_listings_ids)).reshape(1, -1)\n",
    "        for item_embeddings in seen_item_embeddings:\n",
    "            curr_cosine_scores = cosine_similarity(city_active_listings_embeddings, [item_embeddings]).reshape(1, -1)\n",
    "            max_cosine_scores = np.maximum(curr_cosine_scores, max_cosine_scores)\n",
    "        similarity_indices = np.argsort(-max_cosine_scores)\n",
    "        similar_cars_cosine_scores = max_cosine_scores\n",
    "        city_active_listings_ids = np.array(city_active_listings_ids)\n",
    "        similar_listings = city_active_listings_ids[similarity_indices].ravel()\n",
    "        listings.append(similar_listings[:4])\n",
    "    f = pd.DataFrame(listings)\n",
    "    f.columns = [\"Listing ID\", \"Reco - 1\", \"Reco - 2\", \"Reco - 3\"]\n",
    "    f.to_csv('kkk.csv', encoding='utf-8', index=False)\n",
    "    return f\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
